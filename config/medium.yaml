# target size is ~500M parameters. don't decrease hidden size for GLU.
vocab_size: 32768
seq_len: 512
d_model: 1024
d_ffn: 3072
d_qkv: 64
n_heads: 16
n_layers: 10
attn_dropout: 0.0
dropout: 0.0
tie_weights: False # might not play nice with torch.compile
emb_scale_factor: 1.0
weight_init_scale: 0.01